---
layout: post
title:  "HBase分布式环境安装部署"
date:   2017-09-06 15:09:08 +0800
categories: Hadoop
tags: HBase
author: jeff
mathjax: true
---

* content
{:toc}


# 实验说明
* 我们在之前成功搭建Hadoop集群上继续操作，有了这个基础再安装HBase应该就比较简单了

* 节点角色<br>
    h1，h2：Master    
    h3，h4，h5：RegionServer
    
* 实验如未说明则在h1上使用hadoop用户操作

# 扩展（可选）
**背景介绍：ansible是新出现的自动化运维工具，基于Python开发，集合了众多运维工具（puppet、cfengine、chef、func、fabric）的优点，实现了批量系统配置、批量程序部署、批量运行命令等功能。**
* 1 我们在h1节点上使用root用户安装ansible    
    yum install -y epel-release<br>
    yum install -y ansible
    
* 2 配置服务器组，在文件最下面添加<br>
    vim /etc/ansible/hosts    
    ![](http://ov7z79pcc.bkt.clouddn.com/15047840690541.jpg)
    
* 3 Linux用户目录.ssh下的known_hosts文件中有了不同的key时，忽略错误提醒    
    vim /etc/ansible/ansible.cfg    
    ![](http://ov7z79pcc.bkt.clouddn.com/15047942950128.jpg)
    
* 4 切换回hadoop用户测试，没问题的话我们之后很多操作都可以使用它来对多台机器进行统一操作了    
    ansible all -m ping    
    ![](http://ov7z79pcc.bkt.clouddn.com/15047843429405.jpg)
    
# HBase集群安装
* 1 下载HBase并解压安装    
    cd /home/hadoop/app/<br>
    wget http://apache.ip-guide.com/hbase/1.2.6/hbase-1.2.6-bin.tar.gz    
    tar zxf hbase-1.2.6-bin.tar.gz    
    mv hbase-1.2.6 hbase
    
* 2 切换到root用户编辑/etc/profile，配置HBase环境变量    
    
```xml
JAVA_HOME=/home/hadoop/app/jdk
HADOOP_HOME=/home/hadoop/app/hadoop
ZOOKEEPER_HOME=/home/hadoop/app/zookeeper
HBASE_HOME=/home/hadoop/app/hbase
CLASSPATH=.:$JAVA_HOME/lib/dt/jar:$JAVA_HOME/lib/tools.jar
PATH=$JAVA_HOME/bin:$HADOOP_HOME/bin:$ZOOKEEPER_HOME/bin:$HBASE_HOME/bin:$PATH
export JAVA_HOME CLASSPATH PATH HADOOP_HOME ZOOKEEPER_HOME HBASE_HOME
```

* 3 读取配置使其生效，并将配置文件传到其他4个节点且使其生效，操作完成后再次切换回hadoop用户    
    . /etc/profile    
    ansible other -m copy -a "src=/etc/profile dest=/etc/"
    ![](http://ov7z79pcc.bkt.clouddn.com/15047846941434.jpg)

* 4 修改HBase配置regionservers文件    
    cd /home/hadoop/app/hbase/conf/    
    vim regionservers    
    ![](http://ov7z79pcc.bkt.clouddn.com/15046839563708.jpg)

* 5 配置HBase master的备份节点    
    vim backup-masters    
    ![](http://ov7z79pcc.bkt.clouddn.com/15046840466772.jpg)

* 6 配置hbase-site.xml    
    
```xml
<configuration>
	<property>
        <name>hbase.zookeeper.quorum</name>
        <value>h1,h2,h3,h4,h5</value>
        <!-- 指定ZooKeeper集群位置 -->
    </property>
    <property>
            <name>hbase.zookeeper.property.dataDir</name>
            <value>/home/hadoop/data/zookeeper</value>
            <!-- Zookeeper写数据目录（与ZooKeeper集群上配置相一致）-->
    </property>
    <property>
            <name>hbase.zookeeper.property.clientPort</name>
            <value>2181</value>
            <!-- Zookeeper的端口号 -->
    </property>
	<property>
            <name>hbase.rootdir</name>
            <value>hdfs://cluster1/hbase</value>
            <!-- RegionServers 共享目录 -->
    </property>
    <property>
            <name>hbase.cluster.distributed</name>
            <value>true</value>
            <!-- 开启分布式模式 -->
    </property>
    <property>
            <name>hbase.master</name>
            <value>hdfs://h1:60000</value>
            <!-- 指定Hbase的master的位置 -->
    </property>
</configuration>
```    
**备注：配置这个hbase.rootdir属性的时候，需要将hdfs的core-site.xml和hdfs-site.xml两个配置文件copy到hbase的conf或者lib目录下，否则regionserver不能识别cluster逻辑名称。**

* 7 配置hbase-env.sh，增加如下配置<br>
    vim hbase-env.sh    
    
```xml
# 配置jdk安装路径
export JAVA_HOME=/home/hadoop/app/jdk
# 使用独立的Zookeeper集群
export HBASE_MANAGES_ZK=false
```

* 8 Hbase安装包远程同步到其它节点    
    ansible other -m synchronize -a "src=/home/hadoop/app/hbase dest=/home/hadoop/app/"    
    ![](http://ov7z79pcc.bkt.clouddn.com/15047933674608.jpg)    
    
* 9 启动Hbase集群，这里我通过ansible定义了几个快捷命令，直接点击按钮即可使用    
    ![](http://ov7z79pcc.bkt.clouddn.com/15047935025796.jpg)
    
    * 在h1主机内点击启动zookeeper的快捷按钮
        ![](http://ov7z79pcc.bkt.clouddn.com/15047935851560.jpg)
    
    * 在h1上启动HDFS    
        /home/hadoop/app/hadoop/sbin/start-dfs.sh
    
    * 在h1上启动Hbase    
        start-hbase.sh
        
    * 在h1主机内点击查看jps的快捷按钮    
        ![](http://ov7z79pcc.bkt.clouddn.com/15047938434819.jpg)
        ![](http://ov7z79pcc.bkt.clouddn.com/15047938624470.jpg)

* 10 通过web ui查看HBase    
    http://h1:16010/    
    http://h2:16010/    
    ![](http://ov7z79pcc.bkt.clouddn.com/15046947775496.jpg)
    ![](http://ov7z79pcc.bkt.clouddn.com/15046947961620.jpg)


