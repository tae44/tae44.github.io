---
layout: post
title:  "搭建Hadoop分布式集群"
date:   2017-09-01 21:15:20 +0800
categories: Hadoop
tags: 分布式集群
author: Jeff
mathjax: true
---

* content
{:toc}


# 环境介绍
* 1 系统及使用软件    
    Centos6.8 64位系统    
    hadoop-2.6.0    
    Java-1.7.80    
    zookeeper-3.4.9

* 2 实验拓扑及实验注意事项<br>
    h1,h2: namenode,resourcemanager,journalnode,zookeeper    
    h3,h4,h5: datanode,journalnode,zookeeper    
    **PS: Journalnode和ZooKeeper保持奇数个，最少不少于3个节点。实验中使用的安装包，如未给出下载地址，请自行去官网下载。以下操作如未说明，则需要在5台机器上分别操作，截图则一般以h1为主。当创建好hadoop用户后，如未说明则操作一律使用hadoop用户进行。** 
    ![](http://ov7z79pcc.bkt.clouddn.com/15043115750991.jpg)

# 基础配置
* 1 关闭防火墙和selinux    
    chkconfig iptables off    
    vim /etc/selinux/config    
    ![](http://ov7z79pcc.bkt.clouddn.com/15037291026190.jpg)
    
* 2 修改hostname，并将域名和ip的映射关系写入hosts文件    
    vim /etc/sysconfig/network（其他4台改为自己的主机名）    
    ![](http://ov7z79pcc.bkt.clouddn.com/15037291270890.jpg)<br>
    vim /etc/hosts<br>
    ![](http://ov7z79pcc.bkt.clouddn.com/15043120325447.jpg)

* 3 同步系统时间    
    ![](http://ov7z79pcc.bkt.clouddn.com/15037291814068.jpg)
    
* 4 创建hadoop用户，并修改其登录密码    
    useradd -m hadoop<br>
    passwd hadoop<br>
    ![](http://ov7z79pcc.bkt.clouddn.com/15037292020082.jpg)
    
* 5 配置免密码登录，su到hadoop用户<br>
    ![](http://ov7z79pcc.bkt.clouddn.com/15037292207645.jpg)

* 6 生成密钥文件，一路回车即可    
    ssh-keygen –t rsa    
    
* 7 为.ssh目录授权    
    ![](http://ov7z79pcc.bkt.clouddn.com/15037292610825.jpg)
    
* 8 将公钥分别传到5台机器中，分别检查5台机器上是否存有5个公钥<br>
    ssh-copy-id hadoop@h1    
    ssh-copy-id hadoop@h2    
    ssh-copy-id hadoop@h3    
    ssh-copy-id hadoop@h4    
    ssh-copy-id hadoop@h5    
    ![](http://ov7z79pcc.bkt.clouddn.com/15043124613928.jpg)

# 安装JDK
* 1 创建放置软件的目录，并将软件上传    
    mkdir /home/hadoop/app

* 2 解压软件包，并创建软连接    
    tar zxvf java.tar.gz<br>
    ln -s jdk1.7.0_80 jdk
    
* 3 在用户的配置文件中,配置jdk环境变量    
    ![](http://ov7z79pcc.bkt.clouddn.com/15037293678779.jpg)<br>
    重新读取配置文件使其生效 
    . ~/.bashrc
    
* 4 查看是否安装成功    
    ![](http://ov7z79pcc.bkt.clouddn.com/15037294033187.jpg)

# 安装Zookeeper
* 1 首先到官方网站下载ZooKeeper安装包，本实验使用3.4.9版本，将其下载并放到app目录下    
    http://mirrors.cnnic.cn/apache/zookeeper/    
    
* 2 对zookeeper安装包解压    
    tar zxf zookeeper-3.4.9.tar.gz<br>
    mv zookeeper-3.4.9 zookeeper
    
* 3 创建数据目录    
    mkdir -p /home/hadoop/data/zookeeper/zkdata<br>
    mkdir -p /home/hadoop/data/zookeeper/zkdatalog
    
* 4 在ZooKeeper安装目录的conf目录下，创建一个配置文件zoo.cfg    
    cd /home/hadoop/app/zookeeper/conf<br>
    cp zoo_sample.cfg zoo.cfg<br>
    vim zoo.cfg<br>
    **配置内容**<br>
    tickTime=2000<br>
    initLimit=10<br>
    syncLimit=5<br>
    dataDir=/home/hadoop/data/zookeeper/zkdata<br>
    dataLogDir=/home/hadoop/data/zookeeper/zkdatalog<br>
    clientPort=2181<br>
    server.1=h1:2888:3888<br>
    server.2=h2:2888:3888<br>
    server.3=h3:2888:3888<br>
    server.4=h4:2888:3888<br>
    server.5=h5:2888:3888
    
* 5 分别在5台机器上写入myid文件    
    h1: echo 1 > /home/hadoop/data/zookeeper/zkdata/myid<br>
    h2: echo 2 > /home/hadoop/data/zookeeper/zkdata/myid<br>
    h3: echo 3 > /home/hadoop/data/zookeeper/zkdata/myid<br>
    h4: echo 4 > /home/hadoop/data/zookeeper/zkdata/myid<br>
    h5: echo 5 > /home/hadoop/data/zookeeper/zkdata/myid
    
* 6 在每台集群上启动ZooKeeper Server    
    /home/hadoop/app/zookeeper/bin/zkServer.sh start<br>
    zookeeper启动之后，输入jps命令查看进程<br>
    ![](http://ov7z79pcc.bkt.clouddn.com/15043395433450.jpg)

* 7 通过status参数查看每个节点的状态    
    /home/hadoop/app/zookeeper/bin/zkServer.sh status    
    ![](http://ov7z79pcc.bkt.clouddn.com/15043396046137.jpg)
    ![](http://ov7z79pcc.bkt.clouddn.com/15043396200458.jpg)
    ![](http://ov7z79pcc.bkt.clouddn.com/15043396350284.jpg)
    ![](http://ov7z79pcc.bkt.clouddn.com/15043396493235.jpg)
    ![](http://ov7z79pcc.bkt.clouddn.com/15043396636599.jpg)

# hadoop集群环境搭建
* 1 将下载好的hadoop-2.6.0.tar.gz安装包，上传至/home/hadoop/app目录下，解压并创建软链接    
    tar zxvf hadoop-2.6.0.tar.gz    
    ln -s hadoop-2.6.0.tar.gz hadoop
    
* 2 删除没用的软件包，并查看app下现在应该为如下状态    
    ![](http://ov7z79pcc.bkt.clouddn.com/15043401307206.jpg)

* 3 切换到/home/hadoop/app/hadoop/etc/hadoop/目录下，修改配置文件    
    

