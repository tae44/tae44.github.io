---
layout: post
title:  "Hive环境的安装部署"
date:   2017-09-04 22:12:18 +0800
categories: Hadoop
tags: Hive
author: Jeff
mathjax: true
---

* content
{:toc}


# 客户端准备
**PS：从之前主机模板克隆一台使用，减少部署时间。**
* 1 修改主机名    
    vim /etc/sysconfig/network    
    ![](http://ov7z79pcc.bkt.clouddn.com/15045344793464.jpg)

* 2 修改/etc/hosts文件    
    vim /etc/hosts    
    ![](http://ov7z79pcc.bkt.clouddn.com/15045345921034.jpg)

* 3 实现这台机器和集群中每台机器之间的免密码登录    
    * 因为机器为克隆机器，因此已有hadoop用户，su到hadoop用户下面执行<br>
        rm -rf .ssh（如之前有此目录先删除）    
        ssh-keygen -t rsa（一路回车）    
        ssh-copy-id hadoop@h1    
        ssh-copy-id hadoop@h2    
        ssh-copy-id hadoop@h3    
        ssh-copy-id hadoop@h4    
        ssh-copy-id hadoop@h5
        
    * 其他集群机器分别操作
        ssh-copy-id hadoop@hive
        
* 4 把集群的hadoop安装包copy到客户端节点对应的目录下，这就实现了客户端和hadoop集群之间环境的一致性，在h1上用hadoop用户登录并执行下面命令    
    cd /home/hadoop/app<br>
    scp -r hadoop-2.6.0 hive:/home/hadoop/app/
    
* 5 在hive节点配置hadoop的环境变量并使环境变量生效，切换回root用户，并执行如下命令    
    vim /etc/profile    
    ![](http://ov7z79pcc.bkt.clouddn.com/15045355840692.jpg)
    使其生效    
    . /etc/profile

# Mysql安装
* 1 切换回root用户,安装mysql    
    yum -y install mysql-server
    
* 2 启动mysql服务    
    service mysqld start
    
* 3 修改mysql初始root用户密码    
    /usr/bin/mysqladmin -u root password '123456'
    
* 4 使用root登录mysql并创建hive账号    
    mysql -uroot -p123456    
    GRANT ALL ON '*.*' TO 'hive'@'hive' IDENTIFIED BY '123456';    
    FLUSH PRIVILEGES;    
    ![](http://ov7z79pcc.bkt.clouddn.com/15046136209568.jpg)

* 5 查看hive用户是否创建成功    
    SELECT host,user,password FROM mysql.user;    
    ![](http://ov7z79pcc.bkt.clouddn.com/15046136738033.jpg)

* 6 使用hive用户登录mysql数据库，先从刚才root登录的MySQL中退出    
    exit
    mysql -hhive -uhive –p123456    
    ![](http://ov7z79pcc.bkt.clouddn.com/15046139256976.jpg)

* 7 创建数据库hive    
    CREATE DATABASE hive;    
    SHOW DATABASES;    
    ![](http://ov7z79pcc.bkt.clouddn.com/15046140068700.jpg)

# Hive安装
* 1 再次切换回hadoop用户，下载并解压软件    
    su hadoop
    cd /home/hadoop/app/    
    wget http://mirrors.hust.edu.cn/apache/hive/hive-1.2.2/apache-hive-1.2.2-bin.tar.gz    
    tar zxf apache-hive-1.2.2-bin.tar.gz    
    mv apache-hive-1.2.2-bin hive
    
* 2 创建数据目录    
    cd /home/hadoop/app/hive/    
    mkdir iotmp
    
* 3 修改hive配置hive-site.xml，找到如下几个属性进行修改即可    
    cd /home/hadoop/app/hive/conf/    
    cp hive-default.xml.template hive-site.xml    
    vim hive-site.xml    
    
```xml
  <property>
    <name>javax.jdo.option.ConnectionDriverName</name>
    <value>com.mysql.jdbc.Driver</value>
    <!-- 指定驱动 -->
    <description>Driver class name for a JDBC metastore</description>
    </property>
  <property>
    <name>javax.jdo.option.ConnectionURL</name>
    <value>jdbc:mysql://hive:3306/hive?characterEncoding=UTF-8</value>
    <!-- 指定mysql接口 -->
    <description>JDBC connect string for a JDBC metastore</description>
  </property>
  <property>
    <name>javax.jdo.option.ConnectionUserName</name>
    <value>hive</value>
    <!-- mysql用户名 -->
    <description>Username to use against metastore database</description>
  </property>
  <property>
    <name>javax.jdo.option.ConnectionPassword</name>
    <value>123456</value>
    <!-- 登录密码 -->
    <description>password to use against metastore database</description>
  </property>
  <property>
    <name>hive.querylog.location</name>
    <value>/home/hadoop/app/hive/iotmp</value>
    <description>Location of Hive run time structured log file</description>
  </property>
  <property>
    <name>hive.exec.local.scratchdir</name>
    <value>/home/hadoop/app/hive/iotmp</value>
    <description>Local scratch space for Hive jobs</description>
  </property>
  <property>
    <name>hive.downloaded.resources.dir</name>
    <value>/home/hadoop/app/hive/iotmp</value>
    <description>Temporary local directory for added resources in the remote file system.</description>
  </property>
```    

* 4 配置Hive环境变量，切换回root用户编辑/etc/profile文件    
    
```xml
JAVA_HOME=/home/hadoop/app/jdk
HADOOP_HOME=/home/hadoop/app/hadoop
HIVE_HOME=/home/hadoop/app/hive
CLASSPATH=.:$JAVA_HOME/lib/dt/jar:$JAVA_HOME/lib/tools.jar
PATH=$JAVA_HOME/bin:$HADOOP_HOME/bin:$HIVE_HOME/bin:$PATH
export JAVA_HOME CLASSPATH PATH HADOOP_HOME HIVE_HOME
```

* 5 使配置生效后在切换回hadoop用户    
    . /etc/profile
    su hadoop
    
* 6 将mysql驱动包拷贝到hive的lib目录    
    cd
    wget --no-check-certificate https://dev.mysql.com/get/Downloads/Connector-J/mysql-connector-java-5.1.44.tar.gz    
    tar zxf mysql-connector-java-5.1.44.tar.gz    
    cd mysql-connector-java-5.1.44    
    cp mysql-connector-java-5.1.44-bin.jar /home/hadoop/app/hive/lib/
    
* 7 更换jar包，如不更换会报错    
    cd /home/hadoop/app/hive/lib    
    cp jline-2.12.jar /home/hadoop/app/hadoop/share/hadoop/yarn/lib/    
    cd /home/hadoop/app/hadoop/share/hadoop/yarn/lib/    
    rm jline-0.9.94.jar
    
* 8 测试运行hive    
    hive
    ![](http://ov7z79pcc.bkt.clouddn.com/15046162302910.jpg)

    
    

